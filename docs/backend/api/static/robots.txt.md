# Documentação do backend/api/static/robots.txt

## Propósito

Arquivo de configuração para robôs de indexação (web crawlers). Define regras de acesso para mecanismos de busca.

## Exemplo de uso

O arquivo é lido automaticamente por crawlers ao acessar a raiz do domínio.
